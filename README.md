# Wrangle, analyze and visualize tweet data of Twitter handle [@dog_rates](https://twitter.com/dog_rates)

## Introduction
The Twitter handle [@dog_rates](https://twitter.com/dog_rates), also known as "We Rate Dogs" is devoted to humorously reviewing pictures of dogs doing adorable poses, often giving them scores above 10/10. It has acquired more than 7 million followers since its debut.

## Dataset
In this project, I worked on the following three datasets:

- __We Rate Dogs' Enhanced Twitter Archive__: The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything.

- __Additional Data via the Twitter API__ : I gathered this data by using the tweet IDs in the WeRateDogs' Enhanced Twitter archive to query Twitter's API.

- __Image Predictions File__ : Conatins a table full of image predictions that was generated by a neural network algorithm that can classify breeds of dogs (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images). Table columns are described below:

## Summary of Findings 
As I mentioned earlier, most of the dog image attached to each rating tweet by [@dog_rates](https://twitter.com/dog_rates?s=20&t=WVC6h7yzsvn6F21iUlaDOw), was passed through a neural network than can classify a dogs breed from an image of the dog with an average prediction confidence of 62%. I analyzed this neural network predictions and found that the five most popular dog breeds were:

- golden retriever breed
- Labrador retriever breed
- pembroke breed
- chihuahua breed
- pug breed

## Key Insights for Presentation
You can see content on nbviewer: [Jupyter Notebook](https://nbviewer.org/github/10xDatabro/Analysis-of-WeRateDogs-timeline-tweets/blob/main/Wrangle_Act.ipynb)

OR download the HTML files in the subdirectory and view the content offline at anytime in the browser of your local machine.

## Getting Started
> These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. 

### Prerequisites
- You need to be able to work in a Jupyter Notebook on your computer
- You need an installation of Python and the following python libraries need to be installed. (You can install these packages via conda or pip)
  * pandas
  * numpy
  * Matplotlib
  * requests
  * tweepy
  * json

### Installing
These examples tell you how to get a development environment running

I recommend installing Anaconda, which comes with all of the necessary packages, as well as Jupyter Notebook. Here are the installation steps:
- Download the [installer](https://www.anaconda.com/download/). Choose the Python 3.6 or higher version, and the appropriate 64/32-bit installer
- Refer to the installation instructions [here](https://docs.anaconda.com/anaconda/install/)
- Verify the installation, as mentioned [here](https://docs.anaconda.com/anaconda/install/verify-install/)

If you already have Anaconda installed, use the `environment.yaml` to create the exact environment I used during the project by typing the line below into the Anaconda terminal in the same folder where the environment file is saved on your computer

```
conda env create -f environment.yaml
```

 OR If you're not using Conda, you can use pip to install dependencies with the `requirements.txt` file by typing this line into your terminal 

 ```
 pip install -r requirements.txt
 ```

## Built With
- [Anaconda](https://www.anaconda.com/) - Dependency management
- [Jupyter Notebook](https://jupyter.org/) - Data analysis documentation

## Authors
- Gilbert Adikankwu

## License
This project is licensed under the MIT License - see the [LICENSE](https://github.com/10xDatabro/Analysis-of-WeRateDogs-timeline-tweets/blob/main/LICENSE) for details.

## Acknowledgments
- Udacity ALX-T Data Analyst Nanodegree
- [knowyourmeme](https://bit.ly/3C8tk15)
